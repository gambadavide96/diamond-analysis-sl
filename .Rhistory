plot(yhat_tree_1 ,residuals_tree_1) #Previsioni vs dati reali
sqrt(mean((yhat_tree_1 - price_test)^2)) #Test MSE
sqrt(mean((residuals_tree_1)^2)) #Test RMSE
plot(yhat_tree_1 ,Diamonds$price[-train]) #Previsioni vs dati reali
sqrt(mean((residuals_tree_1)^2)) #Test RMSE
#The function
#cv.tree() performs cross-validation in order to determine the optimal level of
#tree complexity; cost complexity pruning is used in order to select a
#sequence of trees for consideration.
cv_tree <- cv.tree(tree_model_1)
#The cv.tree() function reports the number of terminal nodes of each tree considered
#(size) as well as the corresponding error rate and the value of the
#cost-complexity parameter used (k, which corresponds to aplha )
##dev corresponds to the number of cross-validation errors.
cv_tree  #(Valori molto alti!)
plot(cv_tree$size , cv_tree$dev, type = "b")
plot(cv_tree$k , cv_tree$dev, type = "b")
plot(cv_tree$size , cv_tree$dev, type = "b")
plot(cv_tree$k , cv_tree$dev, type = "b")
#prendo la size con errore minore
best = min(cv_tree$size[cv_tree$dev == min(cv_tree$dev)])
#prendo la k con errore minore
k = min(cv_tree$k[cv_tree$dev == min(cv_tree$dev)]) #alpha in the book
#prune the tree
prune_model <- prune.tree(tree_model_1 , best = best)
plot(prune_model)
text(prune_model , pretty = 0)
##### Test MSE on the best sub-tree #####
yhat_prune <- predict(prune_model , newdata = Diamonds[-train , ]) #Predizioni
plot(yhat_prune, price_test) #Previsioni vs dati reali
sqrt(mean((yhat_prune - price_test)^2)) #Test MSE
plot(cv_tree$size , cv_tree$dev, type = "b")
tree_model_1_RMSE = sqrt(mean((residuals_tree_1)^2)) #Test RMSE
prune_model_RMSE = sqrt(mean((yhat_prune - price_test)^2)) #Test RMSE
prune_model_RMSE = sqrt(mean((yhat_prune - price_test)^2)) #Test RMSE
library(randomForest)
library(randomForest)
set.seed(1)
#### Bagging on full Dataset ####
bag_model_1 <- randomForest(price ~ ., data = Diamonds ,
mtry = ncol(Diamonds)-1,
importance = TRUE,
replace=TRUE,
ntree=100) ##Occhio valore di tree
bag_model_1
summary(bag_model_1)
plot(bag_model_1)
importance(bag_model_1)
#### Bagging ####
bag_model_1 <- randomForest(price ~ ., data = Diamonds , subset = train,
mtry = ncol(Diamonds)-1,
importance = TRUE,
replace=TRUE,
ntree=100)
bag_model_1
plot(bag_model_1)
importance(bag_model_1)
yhat_bag_1 <- predict(bag_model_1 , newdata = Diamonds[-train , ])
plot(yhat_bag_1 ,Diamonds$price[-train])
mean((yhat_bag_2 - Diamonds$price[-train])^2) #Test MSE
sqrt(mean((yhat_bag_1 - Diamonds$price[-train])^2)) #Test RMSE
plot(yhat_bag_1 ,yhat_bag_1 - Diamonds$price[-train])
plot(yhat_bag_1 ,Diamonds$price[-train]) #Fiited value vs real value
rf_model_1 <- randomForest(price ~ ., data = Diamonds , subset = train,
mtry = floor(sqrt(ncol(Diamonds)-1)),
importance = TRUE,
replace=TRUE,
ntree=100)
rf_model_1
plot(rf_model_1)
importance(rf_model_1)
#### Confronto Bagging e Random Forest ####
plot(rf_model_1,type = 'b',col="green",pch = "+")
par(new=TRUE) #per sovrapporre grafico
plot(bag_model_2,type = 'b',col="red",pch='o')
plot(bag_model_1,type = 'b',col="red",pch='o')
legend("topright", legend = c("Random Forest", "Bagging"),
col = c("green", "red"), pch = c("+", "o"))
library(gbm)
set.seed(1)
boost_model_1 <- gbm(price ~ ., data = Diamonds[train , ],
distribution = "gaussian",
n.trees = 5000,
interaction.depth = 4)
summary(boost_model_1)
#We can also produce partial dependence plots for these two variables. These plots
#illustrate the marginal effect of the selected variables on the response after
#integrating out the other variables. In this case, as we might expect, the price
#are increasing with both variables.
plot(boost_model_1 , i = "carat")
plot(boost_model_1 , i = "width")
yhat_boost_1 <- predict(boost_model_1 , newdata = Diamonds[-train , ],
n.trees = 5000)
boost_RMSE_1
boost_RMSE_1 <- sqrt(mean((yhat_boost_1 - price_test)^2))
boost_RMSE_1
boost_RMSE_1 <- sqrt(mean((yhat_boost_1 - Diamonds$price[-train])^2))
boost_RMSE_1
##If we want to, we can perform boosting with a different
#value of the shrinkage parameter lambda in (8.10). The default value is 0.001,
#but this is easily modified. Here we take lambda = 0.2.
boost_model_2 <- gbm(price ~ ., data = Diamonds[train , ],
distribution = "gaussian",
n.trees = 5000,
interaction.depth = 4,
shrinkage = 0.02,
verbose=F)
summary(boost_model_2)
plot(boost_model_2 , i = "carat")
plot(boost_model_2 , i = "width")
yhat_boost_2 <- predict(boost_model_2 , newdata = Diamonds[-train , ],
n.trees = 5000)
boost_MSE_2 <- mean((yhat_boost_2 - price_test)^2)
boost_MSE_2
boost_MSE_2 <- sqrt(mean((yhat_boost_2 - price_test)^2))
boost_MSE_2
boost_RMSE_2 <- sqrt(mean((yhat_boost_2 - price_test)^2))
boost_RMSE_2
#Here we apply the best subset selection approach to the Hitters data. We
#wish to predict a baseball player’s Salary on the basis of various statistics
#associated with performance in the previous year.
library ( ISLR2 )
sum(is.na(Hitters$Salary)) #controllo valori mancanti in salary
#Rimuovo valori mancanti
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
#The regsubsets() function (part of the leaps library) performs best sub- set
#selection by identifying the best model that contains a given number
#of predictors, where best is quantified using RSS.
library(leaps)
regfit_full <- regsubsets(Salary ~ ., Hitters)
summary(regfit_full)
#By default, regsubsets() only reports results
#up to the best eight-variable model. But the nvmax option can be used
#in order to return as many variables as are desired.
regfit_full <- regsubsets(Salary ~ ., data = Hitters , nvmax = 19)
reg_summary <- summary(regfit_full) #fino a usare 19 regressori insieme
#We can examine these to try to select the best overall model.
names(reg_summary) #tutte le statistiche fornite
#we see that the R2 statistic increases from 32%, when only
#one variable is included in the model, to almost 55%, when all variables
#are included. As expected, the R2 statistic increases monotonically as more
#variables are included.
reg_summary$rsq
plot(reg_summary$rsq,xlab = "N° regressor",ylab = "R^2")
#Plotting RSS, adjusted R2, Cp, and BIC for all of the models at once will
#help us decide which model to select. Note the type = "l" option tells R to
#connect the plotted points with lines.
par(mfrow = c(2, 2))
plot(reg_summary$rss , xlab = "Number of Variables",
ylab = "RSS", type = "l")
plot(reg_summary$adjr2 , xlab = "Number of Variables",
ylab = "Adjusted RSq", type = "l")
#We will now plot a red dot to indicate the model with the largest
#adjusted R2 statistic.
which.max(reg_summary$adjr2)
points(11, reg_summary$adjr2[11], col = "red", cex = 2, pch = 20)
#In a similar fashion we can plot the Cp and BIC statistics, and indicate the
#models with the smallest statistic using which.min().
plot(reg_summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
which.min(reg_summary$cp)
points(10, reg_summary$cp[10], col = "red", cex = 2, pch = 20)
which.min(reg_summary$bic)
plot(reg_summary$bic , xlab = "Number of Variables", ylab = "BIC", type = "l")
points(6, reg_summary$bic[6], col = "red", cex = 2, pch = 20)
#The regsubsets() function has a built-in plot() command which can
#be used to display the selected variables for the best model with a given
#number of predictors, ranked according to the BIC, Cp, adjusted R2, or AIC.
par(mfrow = c(1, 1))
plot(regfit_full , scale = "r2")
plot(reg_summary$rsq,xlab = "N° regressor",ylab = "R^2")
#We will now plot a red dot to indicate the model with the largest
#adjusted R2 statistic.
which.max(reg_summary$adjr2)
points(11, reg_summary$adjr2[11], col = "red", cex = 2, pch = 20)
regfit_fwd <- regsubsets(Salary ~ ., data = Hitters , nvmax = 19,
method = "forward")
summary(regfit_fwd)
View(Hitters)
summary(regfit_fwd)
regfit_fwd <- regsubsets(Salary ~ ., data = Hitters , nvmax = 19,
method = "forward")
summary(regfit_fwd)
regfit_bwd <- regsubsets(Salary ~ ., data = Hitters , nvmax = 19,
method = "backward")
summary(regfit_bwd)
### Validation approach ###
set.seed(1)
train <- sample(c(TRUE , FALSE), nrow(Hitters), replace = TRUE)
test <- (!train)
#Now, we apply regsubsets() to the training set in order to perform best
#subset selection.
regfit_best <- regsubsets(Salary ~ ., data = Hitters[train , ], nvmax = 19)
#We now compute the validation set error for the best
#model of each model size. We first make a model matrix from the test
#data.
#The model.matrix() function is used in many regression packages for building
#an “X” matrix from data.
test_mat <- model.matrix(Salary ~ ., data = Hitters[test , ])
#Now we run a loop, and for each size i, we
#extract the coefficients from regfit.best for the best model of that size,
#multiply them into the appropriate columns of the test model matrix to
#form the predictions, and compute the test MSE.
val_errors <- rep(NA, 19)
for (i in 1:19) {
coefi <- coef(regfit_best , id = i)
pred <- test_mat[, names(coefi)] %*% coefi
val_errors[i] <- mean((Hitters$Salary[test] - pred)^2)
}
val_errors
#We find that the best model is the one that contains seven variables.
which.min(val_errors)
coef(regfit_best , 7)
#First, we create a vector that allocates each observation to one of
#k = 10 folds, and we create a matrix in which we will store the results.
k <- 10
n <- nrow(Hitters)
set.seed(1)
folds <- sample(rep(1:k, length = n)) #assegna casualmente ad ogni osservazione una fold per la cross-validation.
#Matrice che contiene gli errori
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL , paste (1:19)))
for (j in 1:k) {
best.fit <- regsubsets(Salary ~ .,data = Hitters[folds != j, ], nvmax = 19)
for (i in 1:19) {
pred <- predict(best.fit , Hitters[folds == j, ], id = i)
cv.errors[j, i] <-
mean((Hitters$Salary[folds == j] - pred)^2)
}
}
#Matrice che contiene gli errori
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL , paste (1:19)))
for (j in 1:k) {
best.fit <- regsubsets(Salary ~ .,data = Hitters[folds != j, ], nvmax = 19)
for (i in 1:19) {
pred <- predict(best.fit , Hitters[folds == j, ], id = i)
cv.errors[j, i] <-
mean((Hitters$Salary[folds == j] - pred)^2)
}
}
predict.regsubsets <- function(object , newdata , id, ...) {
form <- as.formula(object$call [[2]])
mat <- model.matrix(form , newdata)
coefi <- coef(object , id = id)
xvars <- names(coefi)
mat[, xvars] %*% coefi
}
regfit_best <- regsubsets(Salary ~ ., data = Hitters ,nvmax = 19)
coef(regfit_best , 7)
k <- 10
n <- nrow(Hitters)
set.seed(1)
folds <- sample(rep(1:k, length = n)) #assegna casualmente ad ogni osservazione una fold per la cross-validation.
#Matrice che contiene gli errori
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL , paste (1:19)))
for (j in 1:k) {
best.fit <- regsubsets(Salary ~ .,data = Hitters[folds != j, ], nvmax = 19)
for (i in 1:19) {
pred <- predict(best.fit , Hitters[folds == j, ], id = i)
cv.errors[j, i] <-
mean((Hitters$Salary[folds == j] - pred)^2)
}
}
#This has given us a 10×19 matrix, of which the (j, i)th element corresponds
#to the test MSE for the jth cross-validation fold for the best i-variable
#model.
cv.errors
#We use the apply() function to average over the columns of this matrix in order
#to obtain a vector for which the apply() ith element is the crossvalidation
#error for the i-variable model.
mean.cv.errors <- apply(cv.errors , 2, mean)
mean.cv.errors
which.min(mean.cv.errors)
plot(mean.cv.errors , type = "b")
#We use the apply() function to average over the columns of this matrix in order
#to obtain a vector for which the apply() ith element is the crossvalidation
#error for the i-variable model.
mean.cv.errors <- apply(cv.errors , 2, mean)
mean.cv.errors
which.min(mean.cv.errors)
plot(mean.cv.errors , type = "b")
which.min(mean.cv.errors)
#We see that cross-validation selects a 10-variable model. We now perform
#best subset selection on the full data set in order to obtain the 10-variable
#model.
reg.best <- regsubsets(Salary ~ ., data = Hitters , nvmax = 19)
coef(reg.best , 10)
################################################################################
######### Setting Dataset
################################################################################
Diamonds <- read.table("diamonds.csv", header = TRUE,
sep = ",",
quote = "\"",
fileEncoding = "UTF-8")
### Transform Categorical Variables as factors
Diamonds$cut <- factor(Diamonds$cut,
levels = c("Fair", "Good", "Very Good", "Premium", "Ideal"))
Diamonds$color <- factor(Diamonds$color,
levels = c("J", "I", "H", "G", "F","E","D"))
Diamonds$clarity <- factor(Diamonds$clarity,
levels=c("I1", "SI2", "SI1", "VS2", "VS1", "VVS2", "VVS1", "IF"))
View(Diamonds)
detect_outlier <- function(x) {
Quantile1 <- quantile(x, probs=.25)
Quantile3 <- quantile(x, probs=.75)
IQR = Quantile3 - Quantile1
x > Quantile3 + (IQR*1.5) | x < Quantile1 - (IQR*1.5)
}
remove_outlier <- function(dataframe,columns=names(dataframe)) {
for (col in columns) {
dataframe <- dataframe[!detect_outlier(dataframe[[col]]), ]
}
print("Remove outliers")
print(dataframe)
}
Diamonds <- remove_outlier(Diamonds, c('carat', 'depth_percentage', 'table', 'price',
"length", 'width', "depth"))
##### Model with interaction terms #####
lm_model_2 = lm(price ~ . + (length:width:depth) , data = Diamonds,
subset = train)
summary(lm_model_2)
#train and test indexes
train <- sample(nrow(Diamonds),floor(nrow(Diamonds)*0.7),replace = FALSE)
price_test <- Diamonds$price[-train]
##### Model with interaction terms #####
lm_model_2 = lm(price ~ . + (length:width:depth) , data = Diamonds,
subset = train)
summary(lm_model_2)
#Test RMSE
fitt_value_lm_2 = predict(lm_model_2,newdata = Diamonds[-train,])
lm_test_RMSE_2 = sqrt(mean((fitt_value_lm_2 - Diamonds$price[-train])^2))
lm_test_RMSE_2
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .(length:width:depth), data = Diamonds[train,],
nvmax = 10,
method = "forward")
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 10,
method = "forward")
summary(model_fwd)
summary(model_fwd)
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
method = "forward")
#preparing data
#creating regressor (automatic handle categorical variables in dummy variables)
x <- model.matrix ( price ~ . +(length : width : depth) ,
Diamonds )[,-1]  #tutte le righe - la prima colonna (intercetta)
View(x)
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24,
method = "forward")
summary(model_fwd)
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24,
method = "best")
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24,
)
summary(model_fwd)
summary(model_fwd)
################################################################################
############################### Subset selection methods
################################################################################
library(leaps)
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24,
method = "forward")
summary(model_fwd)
#R^2
model_fwd$rsq
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24,
method = "forward")
names(reg_summary) #tutte le statistiche fornite
names(model_fwd) #tutte le statistiche fornite
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24,
)
names(model_fwd) #tutte le statistiche fornite
################################################################################
############################### Subset selection methods
################################################################################
library(leaps)
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24,
)
#R^2
model_fwd$rss
plot(reg_summary$rss,xlab = "N° regressor",ylab = "RSS")
plot(model_fwd$rss,xlab = "N° regressor",ylab = "RSS")
library ( ISLR2 )
View(Hitters)
names(Hitters) #nomi features
dim(Hitters)
sum(is.na(Hitters$Salary)) #controllo valori mancanti in salary
#Rimuovo valori mancanti
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
#The regsubsets() function (part of the leaps library) performs best sub- set
#selection by identifying the best model that contains a given number
#of predictors, where best is quantified using RSS.
library(leaps)
regfit_full <- regsubsets(Salary ~ ., Hitters)
summary(regfit_full)
names(reg_summary) #tutte le statistiche fornite
regfit_full <- regsubsets(Salary ~ ., data = Hitters , nvmax = 19)
reg_summary <- summary(regfit_full) #fino a usare 19 regressori insieme
names(reg_summary) #tutte le statistiche fornite
names(summary(model_fwd)) #tutte le statistiche fornite
#R^2
summary(model_fwd)$rsq
plot(model_fwd$rss,xlab = "N° regressor",ylab = "RSS")
plot(summary(model_fwd)$rsq,xlab = "N° regressor",ylab = "RSS")
#R^2
summary(model_fwd)$rsq
###### Forward subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24,
method = "forward")
names(summary(model_fwd)) #tutte le statistiche fornite
#R^2
summary(model_fwd)$rsq
plot(summary(model_fwd)$rsq,xlab = "N° regressor",ylab = "R^2")
#Ajdusted R^2
summary(model_fwd)$adjr2
plot(summary(model_fwd)$adjr2,xlab = "N° regressor",ylab = "R^2")
plot(summary(model_fwd)$adjr2,xlab = "N° regressor",ylab = "R^2")
plot(summary(model_fwd)$rsq,xlab = "N° regressor",ylab = "R^2")
#Ajdusted R^2
summary(model_fwd)$adjr2
#Miglior modello (R^2 più alto)
max_r2 <- which.max(summary(model_fwd)$rsq)
max_r2
points(max_r2, summary(model_fwd)$[max_r2], col = "red", cex = 2, pch = 20)
points(max_r2, summary(model_fwd)$rsq[max_r2], col = "red", cex = 2, pch = 20)
###### Best subset selection ######
model_fwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24)
names(summary(model_fwd)) #tutte le statistiche fornite
#R^2
summary(model_fwd)$rsq
plot(summary(model_fwd)$rsq,xlab = "N° regressor",ylab = "R^2")
#Miglior modello (R^2 più alto)
max_r2 <- which.max(summary(model_fwd)$rsq)
points(max_r2, summary(model_fwd)$rsq[max_r2], col = "red", cex = 2, pch = 20)
#We now compute the validation set error for the best
#model of each model size. We first make a model matrix from the test
#data.
#The model.matrix() function is used in many regression packages for building
#an “X” matrix from data.
test_mat <- model.matrix(price ~ . + (length:width:depth),
data = Diamonds[-train , ])
View(test_mat)
###### Best subset selection ######
model_bwd <- regsubsets(price ~ .+ (length:width:depth), data = Diamonds[train,],
nvmax = 24)
names(summary(model_bwd)) #tutte le statistiche fornite
#R^2
summary(model_bwd)$rsq
plot(summary(model_bwd)$rsq,xlab = "N° regressor",ylab = "R^2")
#Miglior modello (R^2 più alto)
max_r2 <- which.max(summary(model_bwd)$rsq)
points(max_r2, summary(model_bwd)$rsq[max_r2], col = "red", cex = 2, pch = 20)
#Now we run a loop, and for each size i, we
#extract the coefficients from regfit.best for the best model of that size,
#multiply them into the appropriate columns of the test model matrix to
#form the predictions, and compute the test MSE.
val_RMSE <- rep(NA, 24)
for (i in 1:24) {
coefi <- coef(model_bwd , id = i)
pred <- test_mat[, names(coefi)] %*% coefi #prodotto matrici coefficienti per la previsione
val_RMSE[i] <- sqrt(mean((Diamonds$price[-train] - pred)^2))
}
#Supponiamo che test_mat sia una matrice e coefi sia un vettore contenente i nomi
#delle colonne che si desidera selezionare da test_mat. L'espressione test_mat[, names(coefi)]
#restituirà una sotto-matrice di test_mat che contiene solo le colonne il cui
#nome corrisponde ai valori contenuti in coefi.
val_RMSE
#We find that the best model is the one that contains  variables.
best_model_bwd = which.min(val_RMSE)
best_model_bwd
coef(regfit_best , best_model_bwd)
coef(model_bwd , best_model_bwd)
#R^2 e modello con R^2 più alto in grafico
summary(model_bwd)$rsq
plot(summary(model_bwd)$rsq,xlab = "N° regressor",ylab = "R^2")
max_r2 <- which.max(summary(model_bwd)$rsq)
points(max_r2, summary(model_bwd)$rsq[max_r2], col = "red", cex = 2, pch = 20)
#Modello con test RMSE più basso
plot(val_RMSE,xlab = "N° regressor",ylab = "RMSE")
val_RMSE #Test RMSE per tutti i modelli calcolati
#We find that the best model is the one that contains  variables.
min_RMSE = which.min(val_RMSE)
coef(model_bwd , min_RMSE)
min_RMSE
points(min_RMSE, val_RMSE[min_RMSE], col = "blue", cex = 2, pch = 20)
summary(lm_model_2)
View(pred)
coef(model_bwd,1)
#Modello con test RMSE più basso
plot(val_RMSE,xlab = "N° regressor",ylab = " Test RMSE")
points(min_RMSE, val_RMSE[min_RMSE], col = "blue", cex = 2, pch = 20)
